{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/razon1494/ML-Practices/blob/main/Module16_Practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1f45f5d",
      "metadata": {
        "id": "d1f45f5d"
      },
      "source": [
        "# Module 16: Naive Bayes Classifier\n",
        "## Section– Practice Notebook with TODOs\n",
        "\n",
        "This notebook is for **practice**. It is aligned with the teaching notebook for Section 16.5.\n",
        "\n",
        "You will work with two datasets:\n",
        "1. A **synthetic numeric dataset** created with `make_classification` (for GaussianNB).\n",
        "2. A **subset of the 20 Newsgroups text dataset** (for MultinomialNB and BernoulliNB).\n",
        "\n",
        "Where you see `TODO`, write the required code yourself.\n",
        "You can always refer back to the teaching notebook if you get stuck."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "388d69c2",
      "metadata": {
        "id": "388d69c2"
      },
      "outputs": [],
      "source": [
        "# ===============================================================\n",
        "# Imports and basic setup\n",
        "# ===============================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification, fetch_20newsgroups\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (7, 4)\n",
        "sns.set(style='whitegrid')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7eebcc72",
      "metadata": {
        "id": "7eebcc72"
      },
      "source": [
        "## Part A – Gaussian Naive Bayes on Synthetic Numeric Data\n",
        "\n",
        "In this part you will:\n",
        "- Create a synthetic numeric dataset.\n",
        "- Split into train and test sets.\n",
        "- Train a Gaussian Naive Bayes model.\n",
        "- Evaluate the model with accuracy and a confusion matrix.\n",
        "- Experiment by changing the dataset difficulty.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88064fdd",
      "metadata": {
        "id": "88064fdd"
      },
      "outputs": [],
      "source": [
        "# Create a synthetic numeric dataset for binary classification\n",
        "X, y = make_classification(\n",
        "    n_samples=600,\n",
        "    n_features=6,\n",
        "    n_informative=4,\n",
        "    n_redundant=0,\n",
        "    n_clusters_per_class=1,\n",
        "    class_sep=1.6,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print('Shape of X:', X.shape)\n",
        "print('Shape of y:', y.shape)\n",
        "print('Class distribution:', np.bincount(y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e51cbe5",
      "metadata": {
        "id": "1e51cbe5"
      },
      "outputs": [],
      "source": [
        "# TODO 1: Split the data into training and test sets\n",
        "# Use train_test_split with test_size=0.25 and random_state=42\n",
        "# Save the result in X_train, X_test, y_train, y_test\n",
        "\n",
        "# from sklearn.model_selection import train_test_split  # already imported above\n",
        "\n",
        "X_train, X_test, y_train, y_test = ...  # TODO: write the correct function call\n",
        "\n",
        "print('Training set shape:', X_train.shape)\n",
        "print('Test set shape:', X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb6707e0",
      "metadata": {
        "id": "eb6707e0"
      },
      "outputs": [],
      "source": [
        "# TODO 2: Create and train a GaussianNB model\n",
        "# 1. Create an instance of GaussianNB\n",
        "# 2. Fit it on the training data\n",
        "\n",
        "# Example structure:\n",
        "# gnb = GaussianNB()\n",
        "# gnb.fit(X_train, y_train)\n",
        "\n",
        "gnb = ...          # TODO: create the model\n",
        "...\n",
        "# TODO: fit the model on X_train, y_train\n",
        "print('Model training completed.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c2c5ac3",
      "metadata": {
        "id": "9c2c5ac3"
      },
      "outputs": [],
      "source": [
        "# TODO 3: Make predictions on the test set and compute accuracy\n",
        "# 1. Use the trained model to predict on X_test\n",
        "# 2. Compute accuracy_score using y_test and predictions\n",
        "\n",
        "y_pred = ...  # TODO: predictions for X_test\n",
        "acc = ...     # TODO: compute accuracy_score\n",
        "print('Accuracy of GaussianNB on synthetic data:', acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d2288c0",
      "metadata": {
        "id": "8d2288c0"
      },
      "outputs": [],
      "source": [
        "# TODO 4: Compute and plot the confusion matrix\n",
        "# Steps:\n",
        "# 1. Compute confusion_matrix using y_test and y_pred\n",
        "# 2. Print the confusion matrix\n",
        "# 3. Plot it with sns.heatmap\n",
        "\n",
        "cm = ...  # TODO: compute confusion matrix\n",
        "print('Confusion matrix:\\n', cm)\n",
        "\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Gaussian Naive Bayes on Synthetic Numeric Data')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da430219",
      "metadata": {
        "id": "da430219"
      },
      "outputs": [],
      "source": [
        "# TODO 5: Print a classification report\n",
        "# Use classification_report with y_test and y_pred\n",
        "\n",
        "report = ...  # TODO: call classification_report here\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f696556a",
      "metadata": {
        "id": "f696556a"
      },
      "source": [
        "### Experiment: Change the Dataset Difficulty\n",
        "\n",
        "- Recreate the dataset with a smaller `class_sep` value, such as `class_sep=0.8`.\n",
        "- Repeat training and evaluation.\n",
        "- Observe how accuracy and the confusion matrix change.\n",
        "\n",
        "You can copy your previous code cells and adjust only the `make_classification` call."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e637591a",
      "metadata": {
        "id": "e637591a"
      },
      "source": [
        "## Part B – Naive Bayes for Text Classification (20 Newsgroups Subset)\n",
        "\n",
        "In this part you will:\n",
        "- Load a subset of the 20 Newsgroups dataset.\n",
        "- Convert text into numeric features using `CountVectorizer`.\n",
        "- Train a `MultinomialNB` classifier.\n",
        "- Train a `BernoulliNB` classifier with binary features.\n",
        "- Compare their performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4ca25d9",
      "metadata": {
        "id": "f4ca25d9"
      },
      "outputs": [],
      "source": [
        "# Fetch a subset of the 20 Newsgroups dataset\n",
        "categories = ['comp.graphics', 'rec.sport.baseball', 'sci.med'] ## ADD another two more features\n",
        "newsgroups = fetch_20newsgroups(\n",
        "    subset='train',\n",
        "    categories=categories,\n",
        "    remove=('headers', 'footers', 'quotes'),\n",
        "    shuffle=True,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print('Number of documents:', len(newsgroups.data))\n",
        "print('Target names:', newsgroups.target_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "379a68df",
      "metadata": {
        "id": "379a68df"
      },
      "outputs": [],
      "source": [
        "# Put into a DataFrame for easier handling\n",
        "df_text = pd.DataFrame({\n",
        "    'text': newsgroups.data,\n",
        "    'label': newsgroups.target\n",
        "})\n",
        "df_text.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5448a7d4",
      "metadata": {
        "id": "5448a7d4"
      },
      "outputs": [],
      "source": [
        "# TODO 6: Split text data into train and test sets\n",
        "# Use train_test_split on df_text['text'] and df_text['label']\n",
        "# Suggested: test_size=0.25, random_state=42\n",
        "\n",
        "X_train_text, X_test_text, y_train_text, y_test_text = ...  # TODO\n",
        "\n",
        "print('Train size:', X_train_text.shape[0])\n",
        "print('Test size:', X_test_text.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1292bab2",
      "metadata": {
        "id": "1292bab2"
      },
      "outputs": [],
      "source": [
        "# TODO 7: Convert text to count vectors for MultinomialNB\n",
        "# Steps:\n",
        "# 1. Create a CountVectorizer with stop_words='english' and max_features=3000\n",
        "# 2. Fit on X_train_text and transform both train and test sets\n",
        "#    to get X_train_counts and X_test_counts\n",
        "\n",
        "vectorizer = ...  # TODO: create CountVectorizer\n",
        "X_train_counts = ...  # TODO: fit_transform on X_train_text\n",
        "X_test_counts = ...   # TODO: transform on X_test_text\n",
        "\n",
        "print('Shape of X_train_counts:', X_train_counts.shape)\n",
        "print('Shape of X_test_counts:', X_test_counts.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35b1b79e",
      "metadata": {
        "id": "35b1b79e"
      },
      "outputs": [],
      "source": [
        "# TODO 8: Train a MultinomialNB model on the count vectors\n",
        "# 1. Create a MultinomialNB instance\n",
        "# 2. Fit it on X_train_counts and y_train_text\n",
        "\n",
        "mnb = ...  # TODO: create model\n",
        "...\n",
        "# TODO: fit the model\n",
        "print('MultinomialNB model trained on text data.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6836c8d",
      "metadata": {
        "id": "d6836c8d"
      },
      "outputs": [],
      "source": [
        "# TODO 9: Evaluate MultinomialNB\n",
        "# 1. Predict on X_test_counts\n",
        "# 2. Compute accuracy\n",
        "# 3. Compute and print a confusion matrix\n",
        "# 4. Print a classification report with target_names=newsgroups.target_names\n",
        "\n",
        "y_pred_text = ...  # TODO: predictions\n",
        "acc_text = ...     # TODO: accuracy\n",
        "print('Accuracy of MultinomialNB on 20 Newsgroups subset:', acc_text)\n",
        "\n",
        "cm_text = ...      # TODO: confusion matrix\n",
        "print('Confusion matrix:\\n', cm_text)\n",
        "\n",
        "sns.heatmap(cm_text, annot=True, fmt='d', cmap='Greens',\n",
        "            xticklabels=newsgroups.target_names,\n",
        "            yticklabels=newsgroups.target_names)\n",
        "plt.title('MultinomialNB on 20 Newsgroups Subset')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "plt.show()\n",
        "\n",
        "report_text = ...  # TODO: classification_report\n",
        "print(report_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6bcc2802",
      "metadata": {
        "id": "6bcc2802"
      },
      "source": [
        "### 2.1 Practice: Bernoulli Naive Bayes with Binary Features\n",
        "\n",
        "Now repeat a similar process using `BernoulliNB`:\n",
        "- Use `CountVectorizer` with `binary=True`.\n",
        "- Train a `BernoulliNB` model.\n",
        "- Compare its accuracy and confusion matrix with `MultinomialNB`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea33adc3",
      "metadata": {
        "id": "ea33adc3"
      },
      "outputs": [],
      "source": [
        "# TODO 10: Create binary bag of words features\n",
        "# 1. Create a new CountVectorizer with binary=True\n",
        "# 2. Fit on X_train_text and transform train and test sets\n",
        "\n",
        "vectorizer_bin = ...  # TODO: CountVectorizer with binary=True\n",
        "X_train_bin = ...     # TODO: fit_transform\n",
        "X_test_bin = ...      # TODO: transform\n",
        "\n",
        "print('Shape of X_train_bin:', X_train_bin.shape)\n",
        "print('Shape of X_test_bin:', X_test_bin.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30a630d8",
      "metadata": {
        "id": "30a630d8"
      },
      "outputs": [],
      "source": [
        "# TODO 11: Train and evaluate BernoulliNB\n",
        "# Steps:\n",
        "# 1. Create a BernoulliNB model\n",
        "# 2. Fit it on X_train_bin and y_train_text\n",
        "# 3. Predict on X_test_bin\n",
        "# 4. Compute accuracy, confusion matrix, and classification report\n",
        "# 5. Compare the results with MultinomialNB\n",
        "\n",
        "bnb = ...  # TODO: create BernoulliNB model\n",
        "...\n",
        "# TODO: fit the model\n",
        "y_pred_bin = ...  # TODO: predictions\n",
        "acc_bin = ...     # TODO: accuracy\n",
        "print('Accuracy of BernoulliNB on 20 Newsgroups subset:', acc_bin)\n",
        "\n",
        "cm_bin = ...      # TODO: confusion matrix\n",
        "print('Confusion matrix:\\n', cm_bin)\n",
        "\n",
        "sns.heatmap(cm_bin, annot=True, fmt='d', cmap='Purples',\n",
        "            xticklabels=newsgroups.target_names,\n",
        "            yticklabels=newsgroups.target_names)\n",
        "plt.title('BernoulliNB on 20 Newsgroups Subset')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "plt.show()\n",
        "\n",
        "report_bin = ...  # TODO: classification_report\n",
        "print(report_bin)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0953abad",
      "metadata": {
        "id": "0953abad"
      },
      "source": [
        "## Final Reflection\n",
        "\n",
        "- Which model worked better on the text data, **MultinomialNB** or **BernoulliNB**?\n",
        "- How did changing the dataset difficulty in Part A affect the performance of GaussianNB?\n",
        "- Where do you think Naive Bayes will perform well in real projects (for example, spam detection, topic classification)?\n",
        "\n",
        "Write a few short notes summarizing your observations."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}